data:
  activations_harvester:
    llms:
      - name: EleutherAI/pythia-160M
        revision: step142000
    harvesting_batch_size: 1
transcoder:
  n_latents: 8192
train:
  num_steps: 100
  batch_size: 32
  log_every_n_steps: 10
  final_lambda_s: 5
  lambda_s_num__steps: 1000
experiment_name: l1_crosslayer_transcoder_example
in_hookpoint: "blocks.7.mlp.hook_pre"
out_hookpoints: [
  "blocks.7.mlp.hook_post",
  "blocks.8.mlp.hook_post",
]